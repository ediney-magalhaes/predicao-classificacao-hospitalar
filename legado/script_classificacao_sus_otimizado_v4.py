# -*- coding: utf-8 -*-
"""script_classificacao_sus_otimizado_v4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s3V0d4_kFOapysTQ_kqWTG6Jy_kqklKT
"""

# SCRIPT COMPLETO E DEFINITIVO: Treinamento Robusto com Filtro de Data e SMOTE + Predição

import pandas as pd
import re
import gc
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import lightgbm as lgb
from sklearn.metrics import classification_report, accuracy_score

# ==============================================================================
# --- CONFIGURAÇÃO ---
# VVVV Altere o nome do arquivo de entrada aqui VVVV
NOME_ARQUIVO_PARA_PREVER = 'outubro_2025_saidas.csv'
# VVVV Altere o nome do arquivo de saída aqui VVVV
NOME_ARQUIVO_SAIDA = 'outubro_2025_com_previsoes_corrigido_smote_final.csv'
# ==============================================================================

# --- Funções Auxiliares ---
def get_existing_features(df, feature_list):
    return [f for f in feature_list if f in df.columns]

# --- PARTE A: TREINAMENTO E AVALIAÇÃO (COM SMOTE E FILTRO DE DATA) ---
print("--- Verificando a existência dos modelos treinados ---")

NOME_MODELO_GRUPO = 'modelo_grupo_sus_smote.joblib'
NOME_MODELO_COMPLEXIDADE = 'modelo_complexidade_sus_smote.joblib'

if not os.path.exists(NOME_MODELO_GRUPO) or not os.path.exists(NOME_MODELO_COMPLEXIDADE):
    print("Modelos não encontrados. Iniciando treinamento...")

    try:
        df_historico = pd.read_csv('historico_saidas(ajustado).csv', encoding='latin-1', sep=';', low_memory=False)
        print(f"Arquivo histórico completo carregado com {len(df_historico)} linhas.")
    except Exception as e:
        raise ValueError(f"Não foi possível ler o arquivo historico_saidas(ajustado).csv: {e}")

    # --- FILTRO DE JANELA DESLIZANTE (NOVO) ---
    # Com base na nossa análise de drift, vamos usar apenas dados recentes (2020+)
    # Assumindo que a coluna de ano se chama 'ANO' (como você confirmou)
    ANO_DE_CORTE = 2020

    if 'ANO' in df_historico.columns:
        print(f"Filtrando dados históricos para usar apenas de {ANO_DE_CORTE} em diante...")
        df_historico = df_historico[df_historico['ANO'] >= ANO_DE_CORTE].copy()
        print(f"Total de linhas para treinamento (pós-filtro de ano): {len(df_historico)}")
    else:
        print("AVISO: Coluna 'ANO' não encontrada. O modelo será treinado com o histórico completo.")
    # --- FIM DO FILTRO ---

    print("Realizando pré-processamento dos dados históricos...")
    df_historico.columns = map(str.lower, df_historico.columns)
    # df_historico['capitulo_cid'] = df_historico['cid_1_principal'].astype(str).str[0] # Esta linha já deve estar no seu script, se não, descomente
    colunas_para_limpar = ['grupo_sus', 'complexidade_sus', 'idade', 'sexo', 'nr_dias_internacao']
    df_historico.dropna(subset=[col for col in colunas_para_limpar if col in df_historico.columns], inplace=True)

    print("\nLimpando classes extremamente raras (pós-filtro)...")
    min_samples = 10

    for col in ['grupo_sus', 'complexidade_sus']:
        counts = df_historico[col].value_counts()
        to_remove = counts[counts < min_samples].index
        if not to_remove.empty:
            print(f"Removendo {len(to_remove)} classes raras da coluna '{col}': {list(to_remove)}")
            df_historico = df_historico[~df_historico[col].isin(to_remove)]

    print(f"Tamanho do dataset após limpeza final: {len(df_historico)} linhas.")

    df_train, df_test = train_test_split(df_historico, test_size=0.2, random_state=42, stratify=df_historico['complexidade_sus'])
    print(f"\nDados divididos em {len(df_train)} para treino e {len(df_test)} para avaliação.")
    del df_historico
    gc.collect()

    print("Definindo o pipeline de pré-processamento...")
    features_categoricas = ['cid_entrada', 'procedimento_entrada', 'cid_1_principal', 'cirurgia', 'capitulo_cid', 'sexo', 'medico_resp_atend']
    features_numericas = ['idade', 'nr_dias_internacao']
    preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), get_existing_features(df_train, features_numericas)), ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), get_existing_features(df_train, features_categoricas))], remainder='drop')

    print("\nTreinando e salvando modelo para GRUPO_SUS com SMOTE...")
    pipeline_grupo_sus = ImbPipeline([
        ('preprocessor', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('classifier', lgb.LGBMClassifier(random_state=42, n_jobs=-1))
    ])
    pipeline_grupo_sus.fit(df_train, df_train['grupo_sus'])
    joblib.dump(pipeline_grupo_sus, NOME_MODELO_GRUPO)
    print(f">> Modelo '{NOME_MODELO_GRUPO}' salvo.")

    print("\nTreinando e salvando modelo para COMPLEXIDADE_SUS com SMOTE...")
    pipeline_complexidade_sus = ImbPipeline([
        ('preprocessor', preprocessor),
        ('smote', SMOTE(random_state=42)),
        ('classifier', lgb.LGBMClassifier(random_state=42, n_jobs=-1))
    ])
    pipeline_complexidade_sus.fit(df_train, df_train['complexidade_sus'])
    joblib.dump(pipeline_complexidade_sus, NOME_MODELO_COMPLEXIDADE)
    print(f">> Modelo '{NOME_MODELO_COMPLEXIDADE}' salvo.")

    print("\n--- AVALIANDO PERFORMANCE DOS NOVOS MODELOS (COM SMOTE E DADOS RECENTES) ---")
    gs_preds_eval = pipeline_grupo_sus.predict(df_test)
    cs_preds_eval = pipeline_complexidade_sus.predict(df_test)
    print("\nRelatório de Avaliação para GRUPO_SUS (com SMOTE):")
    print(classification_report(df_test['grupo_sus'], gs_preds_eval, zero_division=0))
    print("\nRelatório de Avaliação para COMPLEXIDADE_SUS (COM SMOTE):")
    print(classification_report(df_test['complexidade_sus'], cs_preds_eval, zero_division=0))

else:
    print("Modelos com SMOTE já existem. Pulando o treinamento.")


# --- PARTE B: PREDIÇÃO EM NOVOS DADOS ---
print(f"\n--- Iniciando predição no arquivo '{NOME_ARQUIVO_PARA_PREVER}' ---")

try:
    pipeline_grupo_sus = joblib.load(NOME_MODELO_GRUPO)
    pipeline_complexidade_sus = joblib.load(NOME_MODELO_COMPLEXIDADE)

    df_para_prever = pd.read_csv(NOME_ARQUIVO_PARA_PREVER, encoding='latin-1', sep=';', low_memory=False)
    df_final = df_para_prever.copy()
    print("Modelos (SMOTE) e arquivo de predição carregados.")

    df_para_prever.columns = map(str.lower, df_para_prever.columns)
    if 'cid_1_principal' in df_para_prever.columns:
        df_para_prever['capitulo_cid'] = df_para_prever['cid_1_principal'].astype(str).str[0]

    features_esperadas = ['cid_entrada', 'procedimento_entrada', 'cid_1_principal', 'cirurgia', 'capitulo_cid', 'sexo', 'medico_resp_atend', 'idade', 'nr_dias_internacao']
    for col in features_esperadas:
        if col not in df_para_prever.columns:
            df_para_prever[col] = 0 if col in ['idade', 'nr_dias_internacao'] else 'DESCONHECIDO'

    print("Realizando previsões...")
    df_final['GRUPO_SUS_PREVISTO'] = pipeline_grupo_sus.predict(df_para_prever)
    df_final['COMPLEXIDADE_PREVISTA'] = pipeline_complexidade_sus.predict(df_para_prever)

    ### INÍCIO DA CORREÇÃO FINAL ###
    print("Aplicando regra de negócio de override para 'Cirurgia'...")
    if 'cirurgia' not in df_para_prever.columns: df_para_prever['cirurgia'] = 'DESCONHECIDO'
    df_para_prever['cirurgia'] = df_para_prever['cirurgia'].astype(str).fillna('')

    valores_nao_cirurgicos = ['DESCONHECIDO', 'NAO_CIRURGICO', 'nan', '', '-']

    condicao_cirurgia_presente = ~df_para_prever['cirurgia'].isin(valores_nao_cirurgicos)
    condicao_erro_modelo = (df_final['GRUPO_SUS_PREVISTO'] == 'Procedimentos clínicos')
    indices_para_corrigir = df_final[condicao_cirurgia_presente & condicao_erro_modelo].index

    if not indices_para_corrigir.empty:
        print(f"Corrigindo {len(indices_para_corrigir)} previsões onde a regra de cirurgia foi ignorada pelo modelo...")
        df_final.loc[indices_para_corrigir, 'GRUPO_SUS_PREVISTO'] = 'Procedimentos cirúrgicos'
    else:
        print("Nenhuma correção de regra de negócio foi necessária.")
    ### FIM DA CORREÇÃO ###

    df_final.to_csv(NOME_ARQUIVO_SAIDA, index=False, sep=';', encoding='utf-8-sig')
    print(f"\nSUCESSO! As previsões foram salvas no arquivo: '{NOME_ARQUIVO_SAIDA}'")

except FileNotFoundError:
    print(f"\nERRO: O arquivo '{NOME_ARQUIVO_PARA_PREVER}' não foi encontrado.")
except Exception as e:
    print(f"\nOcorreu um erro durante a predição: {e}")